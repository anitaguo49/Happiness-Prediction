{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run Mod_4_RE_Int_AG.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "should have one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target and predictors\n",
    "outcome = 'Total_Return'\n",
    "x_cols = list(int_df.columns)\n",
    "x_cols.remove(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(int_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train), len(test))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the training data\n",
    "predictors = '+'.join(x_cols)\n",
    "formula = outcome + '~' + predictors\n",
    "model = ols(formula=formula, data=train).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a heat map here\n",
    "sns.heatmap(int_df.corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features which do not appear to be statistically relevant\n",
    "summary = model.summary()\n",
    "p_table = summary.tables[1]\n",
    "p_table = pd.DataFrame(p_table.data)\n",
    "p_table.columns = p_table.iloc[0]\n",
    "p_table = p_table.drop(0)\n",
    "p_table = p_table.set_index(p_table.columns[0])\n",
    "p_table['P>|t|'] = p_table['P>|t|'].astype(float)\n",
    "x_cols = list(p_table[p_table['P>|t|'] < 0.05].index)\n",
    "x_cols.remove('Intercept')\n",
    "print(len(p_table), len(x_cols))\n",
    "print(x_cols[:5])\n",
    "p_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit the model\n",
    "predictors = '+'.join(x_cols)\n",
    "formula = outcome + '~' + predictors\n",
    "model = ols(formula=formula, data=train).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue to refine the model\n",
    "summary = model.summary()\n",
    "p_table = summary.tables[1]\n",
    "p_table = pd.DataFrame(p_table.data)\n",
    "p_table.columns = p_table.iloc[0]\n",
    "p_table = p_table.drop(0)\n",
    "p_table = p_table.set_index(p_table.columns[0])\n",
    "p_table['P>|t|'] = p_table['P>|t|'].astype(float)\n",
    "x_cols = list(p_table[p_table['P>|t|'] < 0.05].index)\n",
    "x_cols.remove('Intercept')\n",
    "print(len(p_table), len(x_cols))\n",
    "print(x_cols[:5])\n",
    "p_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit the model\n",
    "predictors = '+'.join(x_cols)\n",
    "formula = outcome + \"~\" + predictors\n",
    "model = ols(formula=formula, data=train).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code a way to identify multicollinearity\n",
    "X = int_df[x_cols]\n",
    "vif = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "list(zip(x_cols, vif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset features based on multicollinearity\n",
    "vif_scores = list(zip(x_cols, vif))\n",
    "x_cols = [x for x,vif in vif_scores if vif < 5]\n",
    "print(len(vif_scores), len(x_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit model with subset features\n",
    "predictors = '+'.join(x_cols)\n",
    "formula = outcome + \"~\" + predictors\n",
    "model = ols(formula=formula, data=train).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the residuals are normally distributed\n",
    "fig = sm.graphics.qqplot(model.resid, dist=stats.norm, line='45', fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the residuals are homoscedastic\n",
    "plt.scatter(model.predict(train[x_cols]), model.resid)\n",
    "plt.plot(model.predict(train[x_cols]), [0 for i in range(len(train))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers\n",
    "int_df.list_price.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(80,100):\n",
    "    q = i/100\n",
    "    print(\"{} percentile: {}\".format(q, int_df.list_price.quantile(q=q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_tot = len(int_df)\n",
    "# need to edit code to match numbers\n",
    "int_df = int_df[int_df.list_price < 450] # Subsetting to remove extreme outliers\n",
    "\n",
    "print('Percent removed:', (orig_tot -len(int_df))/orig_tot)\n",
    "\n",
    "int_df.list_price = int_df.list_price.map(np.log) # Applying a log transformation\n",
    "train, test = train_test_split(int_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit model with subset features\n",
    "predictors = '+'.join(x_cols)\n",
    "formula = outcome + \"~\" + predictors\n",
    "model = ols(formula=formula, data=train).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check normality assumption\n",
    "fig = sm.graphics.qqplot(model.resid, dist=stats.norm, line='45', fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Homoscedasticity Assumption\n",
    "plt.scatter(model.predict(train[x_cols]), model.resid)\n",
    "plt.plot(model.predict(train[x_cols]), [0 for i in range(len(train))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(80,100):\n",
    "    q = i/100\n",
    "    print(\"{} percentile: {}\".format(q, int_df.list_price.quantile(q=q)))\n",
    "\n",
    "int_df.list_price.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to edit this code\n",
    "int_df = int_df[int_df.list_price <= 6]\n",
    "train, test = train_test_split(int_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit model with subset features\n",
    "predictors = '+'.join(x_cols)\n",
    "formula = outcome + '~' + predictors\n",
    "model = ols(formula=formula, data=train).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Normality Assumption\n",
    "fig = sm.graphics.qqplot(model.resid, dist=stats.norm, line='45', fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Homoscedasticity Assumption\n",
    "\n",
    "plt.scatter(model.predict(train[x_cols]), model.resid)\n",
    "plt.plot(model.predict(train[x_cols]), [0 for i in range(len(train))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "need to run the same things for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the testing data\n",
    "predictors = '+'.join(x_cols)\n",
    "formula = outcome + '~' + predictors\n",
    "model = ols(formula=formula, data=test).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features which do not appear to be statistically relevant\n",
    "summary = model.summary()\n",
    "p_table = summary.tables[1]\n",
    "p_table = pd.DataFrame(p_table.data)\n",
    "p_table.columns = p_table.iloc[0]\n",
    "p_table = p_table.drop(0)\n",
    "p_table = p_table.set_index(p_table.columns[0])\n",
    "p_table['P>|t|'] = p_table['P>|t|'].astype(float)\n",
    "x_cols = list(p_table[p_table['P>|t|'] < 0.05].index)\n",
    "x_cols.remove('Intercept')\n",
    "print(len(p_table), len(x_cols))\n",
    "print(x_cols[:5])\n",
    "p_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit the model\n",
    "predictors = '+'.join(x_cols)\n",
    "formula = outcome + '~' + predictors\n",
    "model = ols(formula=formula, data=test).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue to refine the model\n",
    "summary = model.summary()\n",
    "p_table = summary.tables[1]\n",
    "p_table = pd.DataFrame(p_table.data)\n",
    "p_table.columns = p_table.iloc[0]\n",
    "p_table = p_table.drop(0)\n",
    "p_table = p_table.set_index(p_table.columns[0])\n",
    "p_table['P>|t|'] = p_table['P>|t|'].astype(float)\n",
    "x_cols = list(p_table[p_table['P>|t|'] < 0.05].index)\n",
    "x_cols.remove('Intercept')\n",
    "print(len(p_table), len(x_cols))\n",
    "print(x_cols[:5])\n",
    "p_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit the model\n",
    "predictors = '+'.join(x_cols)\n",
    "formula = outcome + \"~\" + predictors\n",
    "model = ols(formula=formula, data=test).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code a way to identify multicollinearity\n",
    "X = int_df[x_cols]\n",
    "vif = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "list(zip(x_cols, vif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset features based on multicollinearity\n",
    "vif_scores = list(zip(x_cols, vif))\n",
    "x_cols = [x for x,vif in vif_scores if vif < 5]\n",
    "print(len(vif_scores), len(x_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit model with subset features\n",
    "predictors = '+'.join(x_cols)\n",
    "formula = outcome + \"~\" + predictors\n",
    "model = ols(formula=formula, data=train).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the residuals are normally distributed\n",
    "fig = sm.graphics.qqplot(model.resid, dist=stats.norm, line='45', fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the residuals are homoscedastic\n",
    "plt.scatter(model.predict(train[x_cols]), model.resid)\n",
    "plt.plot(model.predict(train[x_cols]), [0 for i in range(len(train))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers\n",
    "int_df.list_price.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(80,100):\n",
    "    q = i/100\n",
    "    print(\"{} percentile: {}\".format(q, int_df.list_price.quantile(q=q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_tot = len(int_df)\n",
    "# need to edit code to match numbers\n",
    "int_df = int_df[int_df.list_price < 450] # Subsetting to remove extreme outliers\n",
    "\n",
    "print('Percent removed:', (orig_tot -len(int_df))/orig_tot)\n",
    "\n",
    "int_df.list_price = int_df.list_price.map(np.log) # Applying a log transformation\n",
    "train, test = train_test_split(int_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit model with subset features\n",
    "predictors = '+'.join(x_cols)\n",
    "formula = outcome + \"~\" + predictors\n",
    "model = ols(formula=formula, data=test).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check normality assumption\n",
    "fig = sm.graphics.qqplot(model.resid, dist=stats.norm, line='45', fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Homoscedasticity Assumption\n",
    "plt.scatter(model.predict(train[x_cols]), model.resid)\n",
    "plt.plot(model.predict(train[x_cols]), [0 for i in range(len(train))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(80,100):\n",
    "    q = i/100\n",
    "    print(\"{} percentile: {}\".format(q, int_df.list_price.quantile(q=q)))\n",
    "\n",
    "int_df.list_price.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to edit this code\n",
    "int_df = int_df[int_df.list_price <= 6]\n",
    "train, test = train_test_split(int_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit model with subset features\n",
    "predictors = '+'.join(x_cols)\n",
    "formula = outcome + '~' + predictors\n",
    "model = ols(formula=formula, data=train).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Normality Assumption\n",
    "fig = sm.graphics.qqplot(model.resid, dist=stats.norm, line='45', fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Homoscedasticity Assumption\n",
    "\n",
    "plt.scatter(model.predict(train[x_cols]), model.resid)\n",
    "plt.plot(model.predict(train[x_cols]), [0 for i in range(len(train))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
